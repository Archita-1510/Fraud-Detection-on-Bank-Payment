{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bank_fraud logistic regression details.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "4b07ZaX1SSr9",
        "outputId": "a907b16c-8bf6-4063-87f3-d7f519c84668"
      },
      "source": [
        "from google.colab import files\n",
        "upload=files.upload()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe490b9b-dfe5-4048-a1cb-8c62f33e38bb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fe490b9b-dfe5-4048-a1cb-8c62f33e38bb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fraud payment data.csv to fraud payment data (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPkEEjBVSZzC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import (SMOTE, RandomOverSampler)\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(upload['fraud payment data.csv']),encoding='latin-1')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "84p1rQGESh8K",
        "outputId": "eeba5751-0a7d-4b47-ec94-78a39eaa69c6"
      },
      "source": [
        "encoder=LabelEncoder()\n",
        "df['customer']=encoder.fit_transform(df['customer'])\n",
        "df['age']=encoder.fit_transform(df['age'])\n",
        "df['gender']=encoder.fit_transform(df['gender'])\n",
        "df['merchant']=encoder.fit_transform(df['merchant'])\n",
        "df['category']=encoder.fit_transform(df['category'])\n",
        "df.drop(['zipcodeOri','zipMerchant'],axis=1,inplace=True)\n",
        "df=df.query('amount>0')\n",
        "df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>customer</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>merchant</th>\n",
              "      <th>category</th>\n",
              "      <th>amount</th>\n",
              "      <th>fraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>210</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>4.55</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2753</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>39.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2285</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>26.89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1650</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>17.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3585</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>35.72</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   step  customer  age  gender  merchant  category  amount  fraud\n",
              "0     0       210    4       2        30        12    4.55      0\n",
              "1     0      2753    2       2        30        12   39.68      0\n",
              "2     0      2285    4       1        18        12   26.89      0\n",
              "3     0      1650    3       2        30        12   17.25      0\n",
              "4     0      3585    5       2        30        12   35.72      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD8DC7VMTu1D",
        "outputId": "679746cf-8aaa-450b-d0f6-819ee964e159"
      },
      "source": [
        "fraud = df[df['fraud']==1]\n",
        "non_fraud = df[df['fraud']==0]\n",
        "print(fraud.shape , non_fraud.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7200, 8) (587391, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaPwu1-iT2tr",
        "outputId": "14aa4f3f-8520-4fed-b90c-a7fb3de4f645"
      },
      "source": [
        "x=df.drop('fraud',axis=1)\n",
        "y=df['fraud']\n",
        "print(x.head())\n",
        "print(y.head())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   step  customer  age  gender  merchant  category  amount\n",
            "0     0       210    4       2        30        12    4.55\n",
            "1     0      2753    2       2        30        12   39.68\n",
            "2     0      2285    4       1        18        12   26.89\n",
            "3     0      1650    3       2        30        12   17.25\n",
            "4     0      3585    5       2        30        12   35.72\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: fraud, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX5xKNrET6sm"
      },
      "source": [
        "x_new=pd.DataFrame(data=df,columns=['amount','category','merchant','gender','age','customer'])\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_new,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-bUOWpZUB5x"
      },
      "source": [
        "def get_report(model,x_train,x_test,y_train,y_test,name,THRESHOLD):\n",
        "  model.fit(x_train,y_train)\n",
        "  y_pred=np.where(model.predict_proba(x_test)[:,1] > THRESHOLD, 1, 0)\n",
        "  print(name,'\\n')\n",
        "  classification_report_m=classification_report(y_test,y_pred)\n",
        "  print(classification_report_m)\n",
        "  confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\n",
        "  print('confusion matrix')\n",
        "  print(confusion_matrix, '\\n')\n",
        "  print('\\n')\n",
        "  print('for test data')\n",
        "  accuracy=accuracy_score(y_test,y_pred)\n",
        "  print('accuracy =',accuracy)\n",
        "  precision_score_m=precision_score(y_test,y_pred)\n",
        "  print('presicion score = ',precision_score_m)\n",
        "  recall_score_m=recall_score(y_test,y_pred)\n",
        "  print('recall score =',recall_score_m)\n",
        "  f1_score_m=f1_score(y_test,y_pred)\n",
        "  print('F1 score =',f1_score_m)\n",
        "  print('\\n')\n",
        "  print('for train data')\n",
        "  y_pred_train=np.where(model.predict_proba(x_train)[:,1] > THRESHOLD, 1, 0)\n",
        "  accuracy_t=accuracy_score(y_train,y_pred_train)\n",
        "  print('accuracy =',accuracy_t)\n",
        "  precision_score_m_t=precision_score(y_train,y_pred_train)\n",
        "  print('presicion score = ',precision_score_m_t)\n",
        "  recall_score_m_t=recall_score(y_train,y_pred_train)\n",
        "  print('recall score =',recall_score_m_t)\n",
        "  f1_score_m_t=f1_score(y_train,y_pred_train)\n",
        "  print('F1 score =',f1_score_m_t)\n",
        "  print('\\n')\n",
        "  print('to understand whether our model is overfitting or underfitting, we can check the f1 scores')\n",
        "  print(f1_score_m_t,' - ',f1_score_m,' = ',f1_score_m_t-f1_score_m)\n",
        "  print('in percentage = ',(f1_score_m_t-f1_score_m)*100)\n",
        "  "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZxyv7_NW_PB",
        "outputId": "41f2fc25-70ff-4a47-fcc6-fd9512c0faad"
      },
      "source": [
        "log_reg=LogisticRegression(max_iter=1000)\n",
        "name='logistic regression on unbalanced data with threshold=0.5'\n",
        "THRESHOLD=0.5\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.5 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    117454\n",
            "           1       0.88      0.58      0.70      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.94      0.79      0.85    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117336    118]\n",
            " [   618    847]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9938109133107409\n",
            "presicion score =  0.877720207253886\n",
            "recall score = 0.5781569965870307\n",
            "F1 score = 0.697119341563786\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9939433054709969\n",
            "presicion score =  0.8775132275132275\n",
            "recall score = 0.5783783783783784\n",
            "F1 score = 0.6972149238045192\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.6972149238045192  -  0.697119341563786  =  9.558224073324961e-05\n",
            "in percentage =  0.009558224073324961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-l2UvWicXxh",
        "outputId": "fb36ea45-28d4-460d-f0ba-788794dc3629"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.1'\n",
        "THRESHOLD=0.1\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.1 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    117454\n",
            "           1       0.62      0.72      0.67      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.81      0.86      0.83    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[116817    637]\n",
            " [   412   1053]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9911788696507707\n",
            "presicion score =  0.6230769230769231\n",
            "recall score = 0.7187713310580205\n",
            "F1 score = 0.6675118858954041\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9916749356699575\n",
            "presicion score =  0.6350220599421877\n",
            "recall score = 0.7278116826503923\n",
            "F1 score = 0.6782580435489113\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.6782580435489113  -  0.6675118858954041  =  0.010746157653507171\n",
            "in percentage =  1.0746157653507171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z75VEeRjC-mf",
        "outputId": "588c3f5b-e600-40a4-d8b5-1afff5fca2fe"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.24'\n",
        "THRESHOLD=0.24\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.24 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    117454\n",
            "           1       0.76      0.65      0.70      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.88      0.82      0.85    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117150    304]\n",
            " [   513    952]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9931297774115154\n",
            "presicion score =  0.7579617834394905\n",
            "recall score = 0.6498293515358362\n",
            "F1 score = 0.6997427416391033\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9935417682773003\n",
            "presicion score =  0.7723460830435672\n",
            "recall score = 0.658413251961639\n",
            "F1 score = 0.7108433734939759\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.7108433734939759  -  0.6997427416391033  =  0.011100631854872534\n",
            "in percentage =  1.1100631854872534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ssiuIqZeUm",
        "outputId": "be14ae99-97cd-44aa-94a6-7e92f4dcbe22"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.25'\n",
        "THRESHOLD=0.25\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.25 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    117454\n",
            "           1       0.77      0.65      0.70      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.88      0.82      0.85    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117172    282]\n",
            " [   518    947]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.993272731859501\n",
            "presicion score =  0.7705451586655818\n",
            "recall score = 0.6464163822525597\n",
            "F1 score = 0.7030438010393467\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9935396659883281\n",
            "presicion score =  0.77579776212184\n",
            "recall score = 0.6528334786399302\n",
            "F1 score = 0.7090237666887604\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.7090237666887604  -  0.7030438010393467  =  0.005979965649413721\n",
            "in percentage =  0.5979965649413721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8kXg5T-Dyng",
        "outputId": "24ff5337-62bb-40ce-83c5-bdab413e67bf"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.26'\n",
        "THRESHOLD=0.26\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.26 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    117454\n",
            "           1       0.77      0.64      0.70      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.88      0.82      0.85    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117178    276]\n",
            " [   522    943]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9932895500298522\n",
            "presicion score =  0.7735849056603774\n",
            "recall score = 0.6436860068259386\n",
            "F1 score = 0.702682563338301\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.993602734657495\n",
            "presicion score =  0.7830109335576114\n",
            "recall score = 0.6493461203138623\n",
            "F1 score = 0.7099418549232676\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.7099418549232676  -  0.702682563338301  =  0.007259291584966521\n",
            "in percentage =  0.7259291584966521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9VKUzYmD63x",
        "outputId": "26397fdd-4fa1-41fd-c38c-45b0119f2179"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.5'\n",
        "THRESHOLD=0.5\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.5 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    117454\n",
            "           1       0.88      0.58      0.70      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.94      0.79      0.85    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117336    118]\n",
            " [   618    847]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9938109133107409\n",
            "presicion score =  0.877720207253886\n",
            "recall score = 0.5781569965870307\n",
            "F1 score = 0.697119341563786\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9939433054709969\n",
            "presicion score =  0.8775132275132275\n",
            "recall score = 0.5783783783783784\n",
            "F1 score = 0.6972149238045192\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.6972149238045192  -  0.697119341563786  =  9.558224073324961e-05\n",
            "in percentage =  0.009558224073324961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6LwWZ_oatOU",
        "outputId": "a2a8e4f0-a66f-4e0d-fabd-6a3019fe9708"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.75'\n",
        "THRESHOLD=0.75\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.75 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    117454\n",
            "           1       0.94      0.50      0.65      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.96      0.75      0.82    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117404     50]\n",
            " [   733    732]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9934156863074866\n",
            "presicion score =  0.9360613810741688\n",
            "recall score = 0.49965870307167237\n",
            "F1 score = 0.651535380507343\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9935459728552448\n",
            "presicion score =  0.9280436877610022\n",
            "recall score = 0.5037489102005231\n",
            "F1 score = 0.6530289330922243\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.6530289330922243  -  0.651535380507343  =  0.0014935525848812636\n",
            "in percentage =  0.14935525848812636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8QwK6yMa8M7",
        "outputId": "c92ca87f-e06d-4afa-bcd6-ab575419ceeb"
      },
      "source": [
        "name='logistic regression on unbalanced data with threshold=0.9'\n",
        "THRESHOLD=0.9\n",
        "get_report(log_reg,x_train,x_test,y_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression on unbalanced data with threshold=0.9 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    117454\n",
            "           1       0.95      0.44      0.60      1465\n",
            "\n",
            "    accuracy                           0.99    118919\n",
            "   macro avg       0.97      0.72      0.80    118919\n",
            "weighted avg       0.99      0.99      0.99    118919\n",
            "\n",
            "confusion matrix\n",
            "[[117422     32]\n",
            " [   825    640]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9927934140044905\n",
            "presicion score =  0.9523809523809523\n",
            "recall score = 0.43686006825938567\n",
            "F1 score = 0.5989705194197473\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9929321044753527\n",
            "presicion score =  0.951655881233346\n",
            "recall score = 0.43591979075850046\n",
            "F1 score = 0.597943075819182\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.597943075819182  -  0.5989705194197473  =  -0.001027443600565281\n",
            "in percentage =  -0.1027443600565281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGkB-4Lh-QJ8"
      },
      "source": [
        "here we observed that, if we do not balance the data, but change the threshold then the following scenario is seen:\n",
        "1. threshold = 0.10 gives f1 score = 0.6675\n",
        "and 1.07% fitting error\n",
        "2. threshold = 0.24 gives f1 score = 0.6997\n",
        "and 1.11% fitting error\n",
        "**3. threshold = 0.25 gives f1 score = 0.7030\n",
        "and 0.59% fitting error**\n",
        "4. threshold = 0.26 gives f1 score = 0.7026\n",
        "and 0.72% fitting error\n",
        "5. threshold = 0.50 gives f1 score = 0.6972\n",
        "and 0.00% fitting error\n",
        "6. threshold = 0.75 gives f1 score = 0.6530\n",
        "and 0.14% fitting error\n",
        "7. threshold = 0.90 gives f1 score = 0.5979\n",
        "and -0.10% fitting error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Xc2K2tJhXb-B",
        "outputId": "0c4b7cad-644e-4db1-87c1-d320d9dcfdc1"
      },
      "source": [
        "cutoff={'threshold':[0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95]}\n",
        "cutoff=pd.DataFrame(cutoff)\n",
        "cutoff['accuracy']=np.nan\n",
        "cutoff['recall']=np.nan\n",
        "cutoff['precision']=np.nan\n",
        "cutoff['f1 score']=np.nan\n",
        "cutoff['difference in accuracy']=np.nan\n",
        "cutoff['difference in f1 score']=np.nan\n",
        "cutoff.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>difference in accuracy</th>\n",
              "      <th>difference in f1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   threshold  accuracy  ...  difference in accuracy  difference in f1 score\n",
              "0       0.05       NaN  ...                     NaN                     NaN\n",
              "1       0.10       NaN  ...                     NaN                     NaN\n",
              "2       0.15       NaN  ...                     NaN                     NaN\n",
              "3       0.20       NaN  ...                     NaN                     NaN\n",
              "4       0.25       NaN  ...                     NaN                     NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBU_zfbVYqv6"
      },
      "source": [
        "def report(THRESHOLD):\n",
        "  log_reg.fit(x_train,y_train)\n",
        "\n",
        "  #for test data\n",
        "  y_pred=np.where(log_reg.predict_proba(x_test)[:,1] > THRESHOLD, 1, 0)\n",
        "  accuracy=accuracy_score(y_test,y_pred)\n",
        "  precision_score_m=precision_score(y_test,y_pred)\n",
        "  recall_score_m=recall_score(y_test,y_pred)\n",
        "  f1_score_m=f1_score(y_test,y_pred)\n",
        "\n",
        "  #for train data\n",
        "  y_pred_train=np.where(log_reg.predict_proba(x_train)[:,1] > THRESHOLD, 1, 0)\n",
        "  accuracy_t=accuracy_score(y_train,y_pred_train)\n",
        "  precision_score_m_t=precision_score(y_train,y_pred_train)\n",
        "  recall_score_m_t=recall_score(y_train,y_pred_train)\n",
        "  f1_score_m_t=f1_score(y_train,y_pred_train)\n",
        "\n",
        "  diff_a=accuracy_t-accuracy\n",
        "  diff_f1=f1_score_m_t-f1_score_m\n",
        "  \n",
        "  cutoff.loc[cutoff['threshold'] == THRESHOLD, 'accuracy'] = accuracy\n",
        "  cutoff.loc[cutoff['threshold'] == THRESHOLD, 'precision'] = precision_score_m\n",
        "  cutoff.loc[cutoff['threshold'] == THRESHOLD, 'recall'] = recall_score_m\n",
        "  cutoff.loc[cutoff['threshold'] == THRESHOLD, 'f1 score'] = f1_score_m\n",
        "  cutoff.loc[cutoff['threshold'] == THRESHOLD, 'difference in accuracy'] = diff_a\n",
        "  cutoff.loc[cutoff['threshold'] == THRESHOLD, 'difference in f1 score'] = diff_f1"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tj_BIZHbUl3"
      },
      "source": [
        "for i in np.arange(0.05,1.0,0.05):\n",
        "  report(i)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "vfVa9Pbjd8jk",
        "outputId": "94961a7c-e7e8-4944-f98e-64f1ee6f518f"
      },
      "source": [
        "cutoff"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>difference in accuracy</th>\n",
              "      <th>difference in f1 score</th>\n",
              "      <th>diff in accuracy in %</th>\n",
              "      <th>diff in f1 score in %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.987538</td>\n",
              "      <td>0.769966</td>\n",
              "      <td>0.496260</td>\n",
              "      <td>0.603531</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.008192</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.991179</td>\n",
              "      <td>0.718771</td>\n",
              "      <td>0.623077</td>\n",
              "      <td>0.667512</td>\n",
              "      <td>0.000496</td>\n",
              "      <td>0.010746</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.992196</td>\n",
              "      <td>0.684642</td>\n",
              "      <td>0.682777</td>\n",
              "      <td>0.683708</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.014023</td>\n",
              "      <td>0.054863</td>\n",
              "      <td>1.402320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.992751</td>\n",
              "      <td>0.662116</td>\n",
              "      <td>0.725505</td>\n",
              "      <td>0.692363</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.015578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.993273</td>\n",
              "      <td>0.646416</td>\n",
              "      <td>0.770545</td>\n",
              "      <td>0.703044</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.005980</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.993584</td>\n",
              "      <td>0.632765</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>0.708445</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.001799</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.993702</td>\n",
              "      <td>0.615700</td>\n",
              "      <td>0.829044</td>\n",
              "      <td>0.706620</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.001502</td>\n",
              "      <td>0.014080</td>\n",
              "      <td>0.150191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.993752</td>\n",
              "      <td>0.602730</td>\n",
              "      <td>0.845785</td>\n",
              "      <td>0.703866</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.001562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.993786</td>\n",
              "      <td>0.589078</td>\n",
              "      <td>0.863000</td>\n",
              "      <td>0.700203</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.002070</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.993811</td>\n",
              "      <td>0.578157</td>\n",
              "      <td>0.877720</td>\n",
              "      <td>0.697119</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.993760</td>\n",
              "      <td>0.562457</td>\n",
              "      <td>0.890811</td>\n",
              "      <td>0.689540</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.993752</td>\n",
              "      <td>0.548805</td>\n",
              "      <td>0.907449</td>\n",
              "      <td>0.683964</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>-0.001048</td>\n",
              "      <td>0.009455</td>\n",
              "      <td>-0.104801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.993643</td>\n",
              "      <td>0.534471</td>\n",
              "      <td>0.913652</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.012188</td>\n",
              "      <td>-0.006639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.993550</td>\n",
              "      <td>0.518089</td>\n",
              "      <td>0.925610</td>\n",
              "      <td>0.664333</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>-0.000638</td>\n",
              "      <td>0.010716</td>\n",
              "      <td>-0.063848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.993416</td>\n",
              "      <td>0.499659</td>\n",
              "      <td>0.936061</td>\n",
              "      <td>0.651535</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.001494</td>\n",
              "      <td>0.013029</td>\n",
              "      <td>0.149355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.993205</td>\n",
              "      <td>0.476451</td>\n",
              "      <td>0.944520</td>\n",
              "      <td>0.633394</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.993004</td>\n",
              "      <td>0.457338</td>\n",
              "      <td>0.947666</td>\n",
              "      <td>0.616943</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.003141</td>\n",
              "      <td>0.017233</td>\n",
              "      <td>0.314136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.992793</td>\n",
              "      <td>0.436860</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.598971</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>-0.001027</td>\n",
              "      <td>0.013869</td>\n",
              "      <td>-0.102744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.992356</td>\n",
              "      <td>0.396587</td>\n",
              "      <td>0.958746</td>\n",
              "      <td>0.561082</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>-0.001072</td>\n",
              "      <td>0.014499</td>\n",
              "      <td>-0.107174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    threshold  accuracy  ...  diff in accuracy in %  diff in f1 score in %\n",
              "0        0.05  0.987538  ...                    NaN                    NaN\n",
              "1        0.10  0.991179  ...                    NaN                    NaN\n",
              "2        0.15  0.992196  ...               0.054863               1.402320\n",
              "3        0.20  0.992751  ...                    NaN                    NaN\n",
              "4        0.25  0.993273  ...                    NaN                    NaN\n",
              "5        0.30  0.993584  ...                    NaN                    NaN\n",
              "6        0.35  0.993702  ...               0.014080               0.150191\n",
              "7        0.40  0.993752  ...                    NaN                    NaN\n",
              "8        0.45  0.993786  ...                    NaN                    NaN\n",
              "9        0.50  0.993811  ...                    NaN                    NaN\n",
              "10       0.55  0.993760  ...                    NaN                    NaN\n",
              "11       0.60  0.993752  ...               0.009455              -0.104801\n",
              "12       0.65  0.993643  ...               0.012188              -0.006639\n",
              "13       0.70  0.993550  ...               0.010716              -0.063848\n",
              "14       0.75  0.993416  ...               0.013029               0.149355\n",
              "15       0.80  0.993205  ...                    NaN                    NaN\n",
              "16       0.85  0.993004  ...               0.017233               0.314136\n",
              "17       0.90  0.992793  ...               0.013869              -0.102744\n",
              "18       0.95  0.992356  ...               0.014499              -0.107174\n",
              "\n",
              "[19 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "mhobKI6lg361",
        "outputId": "3fe9eeeb-efc5-49de-c8a6-615719a174f9"
      },
      "source": [
        "sns.lineplot(x=cutoff['threshold'],y=cutoff['accuracy'],color='red')\n",
        "sns.lineplot(x=cutoff['threshold'],y=cutoff['precision'],color='green')\n",
        "sns.lineplot(x=cutoff['threshold'],y=cutoff['recall'],color='blue')\n",
        "sns.lineplot(x=cutoff['threshold'],y=cutoff['f1 score'],color='orange')\n",
        "plt.ylabel('range')\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "MA2TZ-6WiMW0",
        "outputId": "20bd3ce6-7b3d-48b0-8590-f9109e16d086"
      },
      "source": [
        "cutoff['diff in accuracy in %']=cutoff['difference in accuracy']*100\n",
        "cutoff['diff in f1 score in %']=cutoff['difference in f1 score']*100\n",
        "\n",
        "sns.lineplot(x=cutoff['threshold'],y=cutoff['diff in accuracy in %'])\n",
        "sns.lineplot(x=cutoff['threshold'],y=cutoff['diff in f1 score in %'])\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSPZcdIGbJEf",
        "outputId": "0c20350f-7942-492e-cd07-15610fc9f55c"
      },
      "source": [
        "rus=RandomUnderSampler()\n",
        "x2_train,y2_train=rus.fit_sample(x_train,y_train)\n",
        "np.bincount(y2_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5735, 5735])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bsR9db9di3R",
        "outputId": "86d7764f-9fdb-4fa0-87e8-c43dddae07a6"
      },
      "source": [
        "ros = RandomOverSampler()\n",
        "x3_train,y3_train=ros.fit_sample(x_train,y_train)\n",
        "np.bincount(y3_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([469937, 469937])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xZsQWErdpts",
        "outputId": "166d8d5f-3ec3-4e71-ac5a-75c1a04edc75"
      },
      "source": [
        "smt=SMOTE()\n",
        "x4_train,y4_train=smt.fit_sample(x_train,y_train)\n",
        "np.bincount(y4_train)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([469937, 469937])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09tdAXAKdsQ4",
        "outputId": "91c62ff1-9e21-4169-9614-ced90320b9d9"
      },
      "source": [
        "name='logistic regression (under sampling)'\n",
        "THRESHOLD=0.5\n",
        "get_report(log_reg,x2_train,x_test,y2_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression (under sampling) \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97    117454\n",
            "           1       0.17      0.88      0.28      1465\n",
            "\n",
            "    accuracy                           0.95    118919\n",
            "   macro avg       0.58      0.91      0.63    118919\n",
            "weighted avg       0.99      0.95      0.96    118919\n",
            "\n",
            "confusion matrix\n",
            "[[111100   6354]\n",
            " [   177   1288]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9450802647180013\n",
            "presicion score =  0.16854226642240253\n",
            "recall score = 0.8791808873720136\n",
            "F1 score = 0.28285933897002313\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9102877070619007\n",
            "presicion score =  0.9429593373493976\n",
            "recall score = 0.8734088927637315\n",
            "F1 score = 0.9068525391509007\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.9068525391509007  -  0.28285933897002313  =  0.6239932001808776\n",
            "in percentage =  62.39932001808776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MmZOlCUd3uc",
        "outputId": "d3cc61eb-1cfb-4416-8b0d-0fd225d22905"
      },
      "source": [
        "name='logistic regression (over sampling)'\n",
        "THRESHOLD=0.5\n",
        "get_report(log_reg,x3_train,x_test,y3_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression (over sampling) \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98    117454\n",
            "           1       0.19      0.88      0.31      1465\n",
            "\n",
            "    accuracy                           0.95    118919\n",
            "   macro avg       0.59      0.91      0.64    118919\n",
            "weighted avg       0.99      0.95      0.97    118919\n",
            "\n",
            "confusion matrix\n",
            "[[111972   5482]\n",
            " [   183   1282]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9523625324800915\n",
            "presicion score =  0.18953282081608516\n",
            "recall score = 0.875085324232082\n",
            "F1 score = 0.31158099404544903\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9131372928711721\n",
            "presicion score =  0.9500752256189017\n",
            "recall score = 0.8721020051623941\n",
            "F1 score = 0.9094203300543877\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.9094203300543877  -  0.31158099404544903  =  0.5978393360089387\n",
            "in percentage =  59.78393360089387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kfhWkzFdmQJ",
        "outputId": "7828880f-e58f-42a5-ccd6-ee92511504ac"
      },
      "source": [
        "name='logistic regression (smote sampling)'\n",
        "THRESHOLD=0.5\n",
        "get_report(log_reg,x2_train,x_test,y2_train,y_test,name,THRESHOLD)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logistic regression (smote sampling) \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97    117454\n",
            "           1       0.17      0.88      0.28      1465\n",
            "\n",
            "    accuracy                           0.95    118919\n",
            "   macro avg       0.58      0.91      0.63    118919\n",
            "weighted avg       0.99      0.95      0.96    118919\n",
            "\n",
            "confusion matrix\n",
            "[[111100   6354]\n",
            " [   177   1288]] \n",
            "\n",
            "\n",
            "\n",
            "for test data\n",
            "accuracy = 0.9450802647180013\n",
            "presicion score =  0.16854226642240253\n",
            "recall score = 0.8791808873720136\n",
            "F1 score = 0.28285933897002313\n",
            "\n",
            "\n",
            "for train data\n",
            "accuracy = 0.9102877070619007\n",
            "presicion score =  0.9429593373493976\n",
            "recall score = 0.8734088927637315\n",
            "F1 score = 0.9068525391509007\n",
            "\n",
            "\n",
            "to understand whether our model is overfitting or underfitting, we can check the f1 scores\n",
            "0.9068525391509007  -  0.28285933897002313  =  0.6239932001808776\n",
            "in percentage =  62.39932001808776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk8isApRFpL4"
      },
      "source": [
        "1. using under sampling,\n",
        "f1 score = 0.3146,\n",
        "recall = 0.8757,\n",
        "fitting problem = 59.68 \n",
        "\n",
        "2. using over sampling,\n",
        "f1 score = 0.3102,\n",
        "recall = 0.8744,\n",
        "fitting problem = 59.92%\n",
        "\n",
        "3. using smote,\n",
        "f1 score = 0.3146,\n",
        "recall = 0.8757,\n",
        "fitting problem = 59.68%"
      ]
    }
  ]
}